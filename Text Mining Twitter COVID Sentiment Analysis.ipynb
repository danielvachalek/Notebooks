{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gktHCAUUouQ"
      },
      "source": [
        "## S1.  General Business context\t\n",
        "The overall goal of Big hedge fund of America (BFOA) is to use unique data sources to identify market opportunities. One of the key problems the company is trying to solve includes trying to leverage publicly available data to make profitable trades.\n",
        "\n",
        "The firm recently became aware of a study that proved the average cost of a food related type 1 recall in the 20 days after the announcement is a 305 million reduction in market cap, due to negative stock performance. Knowing the potential recall impact before a recall is self-reported to the FDA would allow financial analysts to better predict future stock performance in the time period following the announcement. Given the number of CPG companies and size of the overall market, we project the value of a prediction of this type to be worth at least $10m annually. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQi_xrJIUouV"
      },
      "source": [
        "## S2.  Specific Questions\n",
        "\n",
        "The first question we need to address is whether we have data that is in enough of a usable state to make this prediction even possible. If our data sets are not workable or able to be labeled in a scalable way, then we will never be able to run it through a predictive model to classify products as potential recall risks. The second question is whether we can identify a signal in the text review data that helps us predict when a recall is likely in the next 90 days. \n",
        "\n",
        "90 days was selected as the time frame for a couple of reasons. The first reason is that it is the typical length of a business quarter, and many public companies must set quarterly targets for their investors. The second reason is that the closer the timeframe gets to the recall date the more obvious it probably is that there is a problem. Thus, the insight gets less valuable simply because the evidence is likely more substantial and there is a shorter amount time to act on the information.\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUc4UadIUouX"
      },
      "source": [
        "## S3: Analysis Methods\n",
        "Use at least one text analysis method other than term counts to help answer your question\n",
        "Given what we know about the real time nature of consumers complaining, we have potential data that could be used to generate advanced signal detection of potential recalls. In the initial project sprint, we are using a database of 75 million publicly available amazon reviews, and official FDA recall data from 2012-today. The goal is to identify recalls in the wild in advance of the FDA official recall notices. \n",
        "\n",
        "To generate this likelihood value, we will look at the words in each review and assign positive and negative sentiment scores to different words. More weight will be given to extreme words such as medical events. From this we will calculate the probability of whether the associated product was recalled in the next 90 days from the social comment.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLiDT5cVUouZ"
      },
      "outputs": [],
      "source": [
        "# import modules\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "pd.set_option('display.max_colwidth', 500)\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xdSyIPiGUoua"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "reviewdf = pd.read_json(r'C:\\Users\\anaconda\\downloads\\meta_Pet_Supplies.json.gz',\n",
        "                  compression='infer', lines = True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQxrw-WfUoub"
      },
      "outputs": [],
      "source": [
        "reviewdf.head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZ7c9jMeUouc"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "reviewdf = pd.read_json(r'C:\\Users\\anaconda\\downloads\\All_Amazon_Review_5.json.gz',\n",
        "                  compression='infer', lines = True, chunksize=1000000)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gmAKb91UUoud"
      },
      "outputs": [],
      "source": [
        "userl = [[tweet.full_text, tweet.user.name, tweet.user.created_at, tweet.user.location, tweet.user.followers_count, tweet.user.friends_count] for tweet in tweets]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MrhmMQguUouf"
      },
      "outputs": [],
      "source": [
        "tweetdf = pd.DataFrame(data=userl, columns=['full_text', 'username', 'userCreatedDate', \"location\", 'followers', 'friends'])\n",
        "#tweetdf\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x46ZrlfuUoug"
      },
      "source": [
        "### EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ll-yhLbUouh"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJm8fGoUUoui"
      },
      "outputs": [],
      "source": [
        "tweetdf.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRoIS66-Uouj"
      },
      "outputs": [],
      "source": [
        "#Where are longcovid tweets occuring?\n",
        "location = tweetdf.groupby('location')\n",
        "location.count().sort_values(by=\"full_text\",ascending=False)\n",
        "\n",
        "#Definitely a biased sample based on how we limited lang to EN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZxb5fuRUouk"
      },
      "outputs": [],
      "source": [
        "#any nulls?\n",
        "tweetdf.isnull().sum()\n",
        "#Nope"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12J6prvTUouk"
      },
      "source": [
        "## Q1. \n",
        "Our business question is whether we can identify the most common #longcovid symptoms through text mining. The data we pulled consists of self-reported and anecdotal symptoms from tweets. We did EDA on summaries of numerical data, as well as checking for nulls and looking for the most popular locations where users are tweeting these symptoms. The most frequently counted locations were around the UK region. This is likely due to the fact that we limited our analysis to 'EN' language in our search filter, and that the UK was exposed to COVID-19 before the US.Based on what we want to know, we'll need to account for case, cleaning of hashtags, mentions and urls, as well as custom stop words and stemming for multiple variations of the same symptom. ('fatigue' vs. 'fatigued')\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70K8j7hxUoul"
      },
      "source": [
        "## T2. \n",
        "Perform the preprocessing steps you identified in Q1 and append the results to your original data frame.  Print some examples that help demonstrate the effects of your decisions.  Be sure to identify at least two successes and two ‘mishaps.’ "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fISxZZI8Uoul"
      },
      "outputs": [],
      "source": [
        "# https://pypi.org/project/tweet-preprocessor/\n",
        "# The tweet-preprocessor package looks really useful for this\n",
        "import preprocessor as p\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p-fQBNgQUoum"
      },
      "outputs": [],
      "source": [
        "import re, string, unicodedata\n",
        "#This is an interesting idea I found, builds a column for hashtags and stores in a list. Not relevant for this step, but still interesting...\n",
        "tweetdf['hashtag'] = tweetdf['full_text'].apply(lambda x: re.findall(r\"#(\\w+)\", x))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZM6NVaoaUoum"
      },
      "outputs": [],
      "source": [
        "#function that applies the preprocessing from the tweet-preprocessing package\n",
        "def preprocess_tweet(row):\n",
        "    text = row['full_text']\n",
        "    cleantext = p.clean(text)\n",
        "    return cleantext\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hIqfvmKPUoum"
      },
      "outputs": [],
      "source": [
        "p.set_options(p.OPT.URL, p.OPT.EMOJI, p.OPT.MENTION) #We want to clean out URLs, emojiis and mentions. Given more time, we may want to assign some kind of override logic when an emoji is present, as that could give an easy indication of that particular person's sentiment.\n",
        "tweetdf['cleantext'] = tweetdf.apply(preprocess_tweet, axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GCZDCABbUoun"
      },
      "outputs": [],
      "source": [
        "tweetdf.head(45)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9nDQkymUoun"
      },
      "outputs": [],
      "source": [
        "#Make it lowercase\n",
        "tweetdf['cleantextlower']=tweetdf['cleantext'].apply(lambda x: x.lower())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J2-9EbHpUouo"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "pd.set_option('display.max_rows', 1000)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "\n",
        "#create an object storing the default nltk stopwords\n",
        "nltk_stopwords = stopwords.words(\"english\") \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wY56kEDTUouo"
      },
      "outputs": [],
      "source": [
        "#create a custom stop words list by adding a covid terms to the nltk list\n",
        "my_stopwords = nltk_stopwords + [\"covid\", \"long\", \"longhaulers\", \"still\", \"this\", \"longhaul\", \"get\", \"longcovid\", \"countlongcovid\",\"symptoms\", \"people\",\"covid19\", \"us\", \"also\", \"covid19\", \"amp\",\"many\",\"like\"]\n",
        "\n",
        "cv1 = CountVectorizer(binary = False, stop_words = my_stopwords, ngram_range=(1,5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Qta9ReIUoup"
      },
      "outputs": [],
      "source": [
        "#put it in a list\n",
        "tlist = tweetdf['cleantext'].values.tolist()\n",
        "#print(tlist)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nKSJ1jgrUoup"
      },
      "outputs": [],
      "source": [
        "#cv1\n",
        "cv1_tlist = cv1.fit_transform(tlist)\n",
        "\n",
        "names_cv1 =cv1.get_feature_names()\n",
        "count_cv1_review = np.sum(cv1_tlist.toarray(), axis = 0).tolist() #sum and convert to list\n",
        "count_cv1_review_df = pd.DataFrame(count_cv1_review, index = names_cv1, columns = ['count']) # create a dataframe from the list\n",
        "sorted_count1 = count_cv1_review_df.sort_values(['count'], ascending = False)  #order by count\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B68DAMuaUoup"
      },
      "outputs": [],
      "source": [
        "#This seems like an improvement, at least, as we've removed the highest covid terms.\n",
        "sorted_count1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dNM0iZ0GUouq"
      },
      "outputs": [],
      "source": [
        "#Can we cut down on fragmented counts using stemming?\n",
        "\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "ps = PorterStemmer() \n",
        "\n",
        "def stem_text(row):\n",
        "    text = str(row).split() #splits the text apart before stemming\n",
        "    stemtext = [ps.stem(word) for word in text] #tells it which stemmer to apply and how\n",
        "    stem2text = ' '.join(stemtext) #puts everything back together again\n",
        "    return stem2text\n",
        "\n",
        "tweetdf['cleantextlowerstemmed'] = tweetdf['cleantextlower'].apply(lambda x: stem_text(x)) #apply the above function to our text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E1oW1n4QUouq"
      },
      "outputs": [],
      "source": [
        "cv1_tlist2 = cv1.fit_transform(tweetdf['cleantextlowerstemmed'])\n",
        "\n",
        "names_cv1 =cv1.get_feature_names()\n",
        "count_cv1_review = np.sum(cv1_tlist2.toarray(), axis = 0).tolist() #sum and convert to list\n",
        "count_cv1_review_df = pd.DataFrame(count_cv1_review, index = names_cv1, columns = ['count']) # create a dataframe from the list\n",
        "sorted_count2 = count_cv1_review_df.sort_values(['count'], ascending = False)  #order by count\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4FJVRB09Uouq"
      },
      "outputs": [],
      "source": [
        "#Doesn't appear to be helping reduce complexity...\n",
        "sorted_count2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMgbYsMMUour"
      },
      "outputs": [],
      "source": [
        "\n",
        "#try again with stem\n",
        "cv1_tlist = cv1.fit_transform(tweetdf['cleantextlowerstemmed'])\n",
        "\n",
        "names_cv1 =cv1.get_feature_names()\n",
        "count_cv1_review = np.sum(cv1_tlist.toarray(), axis = 0).tolist() #sum and convert to list\n",
        "count_cv1_review_df = pd.DataFrame(count_cv1_review, index = names_cv1, columns = ['count']) # create a dataframe from the list\n",
        "sorted_count = count_cv1_review_df.sort_values(['count'], ascending = False)  #order by count\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9NA6iOUEUour"
      },
      "outputs": [],
      "source": [
        "sorted_count[0:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bV_GMKSAUour"
      },
      "source": [
        "## Q2. Explain the examples you selected in T2 and whether they reflect the expected results based on your preprocessing decisions.  \n",
        "\n",
        "The results of my decisions didn't necessarily yield desirable results. I was trying to attempt to simplify the fragments using stemming, but for some reason this moved words like 'this' towards the top of my counts. I'm not 100% sure why this occuring since I used a custom stop word list that removed for words like 'this'. I think maybe I'm referencing the wrong stopword variable and I need to go back and double check the reference. I definitely think removing case, emojiis and mentions was worthwhile, so I would probably keep those changes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kJZfd4YUour"
      },
      "source": [
        "## T3. \n",
        "Create a sentiment dictionary from one of the sources in class or find/create your own (potential bonus points for appropriate creativity). Using your dictionary, create sentiment labels for the text entries (raw and processed) in your corpus.  Provide output that demonstrates the class balance (or lack thereof).  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Afevz-SmUous"
      },
      "outputs": [],
      "source": [
        "#class example\n",
        "from afinn import Afinn\n",
        "afinn = Afinn(language='en')\n",
        "\n",
        "afinn.score(\"most day i feel like the uk government, the nhs, and univers upper manag are gaslight me. covid isn't that bad, they say. number go up isn't much of a concern, they say. carri on, they say. #longcovid\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qaBBmO_TUous"
      },
      "outputs": [],
      "source": [
        "#class example\n",
        "\n",
        "def afinn_sent(inputstring):\n",
        "    \n",
        "    sentcount =0\n",
        "    for word in inputstring.split():  \n",
        "        if word.rstrip('?:!.,;') in afinn:\n",
        "            sentcount = sentcount + afinn[word.rstrip('?:!.,;')]\n",
        "            \n",
        "    \n",
        "    if (sentcount < 0):\n",
        "        sentiment = 'Negative'\n",
        "    elif (sentcount > 0):\n",
        "        sentiment = 'Positive'\n",
        "    else:\n",
        "        sentiment = 'Neutral'\n",
        "    \n",
        "    return sentiment\n",
        "    #return sentcount"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Va5hRxp5Uous"
      },
      "outputs": [],
      "source": [
        "def afinn_sent(row):\n",
        "    text = row['cleantextlowerstemmed']\n",
        "    sentscore = afinn.score(text)\n",
        "    return sentscore\n",
        "\n",
        "def afinn_sent_lower(row):\n",
        "    text = row['cleantextlower']\n",
        "    sentscore = afinn.score(text)\n",
        "    return sentscore\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xRirq7vYUout"
      },
      "outputs": [],
      "source": [
        "tweetdf['affin_score'] = tweetdf.apply(afinn_sent, axis=1)\n",
        "tweetdf['affin_score_lower'] = tweetdf.apply(afinn_sent_lower, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JL2O7ZYVUout"
      },
      "outputs": [],
      "source": [
        "tweetdf.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mj0shzDXUout"
      },
      "outputs": [],
      "source": [
        "tweetdf['affin_score'].describe()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1iWaCDZ6Uout"
      },
      "outputs": [],
      "source": [
        "tweetdf['affin_score_lower'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vwRHIHvjUouu"
      },
      "outputs": [],
      "source": [
        "#class example to return sentiment category from afinn score\n",
        "\n",
        "def afinn_sent_cat(inputstring):\n",
        "    if (inputstring < 0):\n",
        "        sentiment = 'Negative'\n",
        "    elif (inputstring > 0):\n",
        "        sentiment = 'Positive'\n",
        "    else:\n",
        "        sentiment = 'Neutral'\n",
        "    \n",
        "    return sentiment\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mizhi5PIUouu"
      },
      "outputs": [],
      "source": [
        "tweetdf['afinn_sentiment'] = tweetdf['affin_score'].apply(afinn_sent_cat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZnUhiwsWUouu"
      },
      "outputs": [],
      "source": [
        "tweetdf['afinn_sentiment_lower'] = tweetdf['affin_score_lower'].apply(afinn_sent_cat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5WPVO-8eUouu"
      },
      "outputs": [],
      "source": [
        "tweetdf.head(500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ASrKBcjXUouv"
      },
      "outputs": [],
      "source": [
        "\n",
        "afinn_sentiment = tweetdf.groupby('afinn_sentiment')\n",
        "afinn_sentiment.count().sort_values(by=\"full_text\",ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EMNxeofuUouv"
      },
      "outputs": [],
      "source": [
        "\n",
        "afinn_sentiment_lower = tweetdf.groupby('afinn_sentiment_lower')\n",
        "afinn_sentiment_lower.count().sort_values(by=\"full_text\",ascending=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jenv-6pUouv"
      },
      "source": [
        "## Q3. \n",
        "We chose to use the afinn method for measuring sentiment, because it seemed like a reasonable starting place due to being more explainable to stakeholders. The afinn sentiment measure is a check for each word from our sample that we can match back to manually coded words, then a sum of those values. I chose this because I like sticking with simple methods first to identify the least complex transformation. \n",
        "\n",
        "It seems like the stemming version almost acted as a regularization method. Overall ended with more neutral sentiment vs. non-stemming. My guess is the stemmed version removed matches from the afinn dictionary. I think I would code a manual dictionary if I was going to try and classify sentiment based on symptoms. There are obvious heart/breathing symptoms in the tweets that I pulled down that are downright alarming, and those should be given more weight than people who have a sunburn sensation. Although, to be honest, it's all very troubling to see.\n",
        "\n",
        "Specific example pulled out below:\n",
        "No stemming (-3 Negative)\n",
        "'does any other #longhauler have phantom sunburn sensations? they keep getting worse and i'm looking for a way to manage them but like wtf do i do? it's not like aloe will help and i tried thc lotion but that was a bust. ibuprofen failed me too. #longcovid #countlongcovid'\n",
        "\n",
        "vs. stemming (0 Neutral)\n",
        "'doe ani other #longhaul have phantom sunburn sensations? they keep get wors and i'm look for a way to manag them but like wtf do i do? it' not like alo will help and i tri thc lotion but that wa a bust. ibuprofen fail me too. #longcovid #countlongcovid'\t\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "DV_TM_Project.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}